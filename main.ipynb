{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T00:32:43.353279Z",
     "start_time": "2025-01-16T00:32:43.326993Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import torch.nn.functional as F\n",
    "from utilities import utils, process, evaluate, modify, plot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T00:31:22.049768Z",
     "start_time": "2025-01-16T00:31:12.547278Z"
    }
   },
   "source": [
    "df = utils.load_images_to_dataframe('data/preprocessed')\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['Target'] = label_encoder.fit_transform(df['Target'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# Further split the training set into training and validation sets\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "df.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                       image  \\\n",
       "filename                                                                       \n",
       "user001_abjadiyah_031.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "user001_abjadiyah_032.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "user001_abjadiyah_033.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "user001_abjadiyah_034.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "user001_abjadiyah_035.png  [[255, 255, 255, 255, 255, 255, 255, 255, 255,...   \n",
       "\n",
       "                           Target  \n",
       "filename                           \n",
       "user001_abjadiyah_031.png       0  \n",
       "user001_abjadiyah_032.png       0  \n",
       "user001_abjadiyah_033.png       0  \n",
       "user001_abjadiyah_034.png       0  \n",
       "user001_abjadiyah_035.png       0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user001_abjadiyah_031.png</th>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user001_abjadiyah_032.png</th>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user001_abjadiyah_033.png</th>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user001_abjadiyah_034.png</th>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user001_abjadiyah_035.png</th>\n",
       "      <td>[[255, 255, 255, 255, 255, 255, 255, 255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T00:45:49.971906Z",
     "start_time": "2025-01-16T00:45:49.946556Z"
    }
   },
   "source": [
    "# Custom Dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Access the stored image data in grayscale\n",
    "        image = self.dataframe.iloc[idx, 0]  # 'image' column has the image data (grayscale)\n",
    "        label = self.dataframe.iloc[idx, 1]  # 'Target' column has the label\n",
    "\n",
    "        # Convert grayscale image to RGB if needed\n",
    "        image = np.expand_dims(image, axis=-1)  # Add channel dimension (H, W, 1)\n",
    "        image = np.repeat(image, 3, axis=-1)  # Convert to RGB by duplicating the grayscale channel\n",
    "\n",
    "        # Convert numpy array to PIL image\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T00:49:16.427076Z",
     "start_time": "2025-01-16T00:49:16.410251Z"
    }
   },
   "cell_type": "code",
   "source": "print(df['Target'].unique())\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tUK96Oh5tsUu",
    "ExecuteTime": {
     "end_time": "2025-01-16T00:56:29.796417Z",
     "start_time": "2025-01-16T00:50:30.514300Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = ImageDataset(dataframe=df, transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, 82)  # Adjust to 82 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 32 * 32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Ensure the labels are of type Long (int64)\n",
    "        labels = labels.long()  # Convert labels to Long type\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}')\n",
    "\n",
    "print('Finished Training')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.9647690782360003\n",
      "Epoch 2, Loss: 2.901468084372726\n",
      "Epoch 3, Loss: 1.6404979584263821\n",
      "Epoch 4, Loss: 0.6163130083504845\n",
      "Epoch 5, Loss: 0.14525239270399598\n",
      "Epoch 6, Loss: 0.024040215950934033\n",
      "Epoch 7, Loss: 0.005312544948366635\n",
      "Epoch 8, Loss: 0.0018021448246002489\n",
      "Epoch 9, Loss: 0.0009643208915732947\n",
      "Epoch 10, Loss: 0.0006225368667704364\n",
      "Finished Training\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "71    100\n",
       "1     100\n",
       "2     100\n",
       "55    100\n",
       "39    100\n",
       "     ... \n",
       "59    100\n",
       "60    100\n",
       "8     100\n",
       "47     94\n",
       "58     50\n",
       "Name: count, Length: 82, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T01:05:32.769773Z",
     "start_time": "2025-01-16T01:05:27.299077Z"
    }
   },
   "source": [
    "test_dataset = ImageDataset(dataframe=test_df, transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# No need to track gradients during inference\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Iterate over the test dataset\n",
    "with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "    for images, labels in test_dataloader:\n",
    "        labels = labels.long()  # Ensure the labels are of type Long (int64)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get the predicted class with the highest probability\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Count correct predictions\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * correct_predictions / total_predictions\n",
    "print(f'Accuracy on the test set: {accuracy:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 100.00%\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPYpJQ3vmTZUsn3auznlQ48",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
